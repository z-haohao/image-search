# Q:
# 我要实现一个将图片向量化存入向量化数据库的项目：
# 1.实现原理为： 从kafka中获取图片的数据相关属性数据: {
#   "product_no": 20141205000036,
#   "brand_no": "BL",
#   "picture_url": "/2015/MDM/BL/BICX1198XU2DX1.jpg"
# }
# 2. 从上述相关属性数据中，找到图片的url连接后，可以去根据url连接去minio中获取图片对象，如果minio中没有当前图片数据，可以根据这个url去图片服务器接口中获取
# 3. 将上述获取的图片，通过resnet50 特征识别转化为2048的向量, 然后将当前向量和图片给的相关属性信息存入milvus向量数据库中。
#
# A:
# 我要通过python实现上述项目，需要将项目代码分为哪些模块，分别实现什么功能，请讲整个项目的需要实现的模块和大纲给我
#
# 要实现您所描述的图片向量化存储的项目，您可以将项目分成以下几个主要模块：
#
#     消息队列监听模块（Kafka消费者）：
#         功能：实时监听Kafka中的消息队列，获取图片数据相关的属性信息。
#         实现：使用confluent-kafka-python库或kafka-python库来实现Kafka消费者。
#
#     图片获取模块：
#         功能：根据从Kafka获取的URL，在MinIO或备用图片服务器上检索图片。
#         实现：使用boto3库（针对MinIO的兼容S3客户端）或requests库（针对普通HTTP服务）来获取图片。
#
#     图像预处理和特征提取模块：
#         功能：将获取的图片转换为适合模型处理的格式，并使用预训练的ResNet50模型提取特征向量。
#         实现：使用PIL或opencv-python库进行图像预处理，使用tensorflow或torchvision库中的ResNet50模型进行特征提取。
#
#     向量存储模块（Milvus客户端）：
#         功能：将提取的特征向量和图片的相关属性信息存入Milvus向量数据库中。
#         实现：使用pymilvus库来实现与Milvus数据库的交互。
#
# 以下是这个项目的实现大纲：
# A. Kafka消息队列监听模块（Kafka消费者）
#
#     连接到Kafka服务器。
#     订阅相关的Kafka主题。
#     持续监听消息，并在接收到消息时触发图片获取流程。
#
# B. 图片获取模块
#
#     解析从Kafka接收到的消息，提取图片URL。
#     首先尝试从MinIO存储中获取图片。
#     如果MinIO中不存在图片，则通过HTTP请求从备用的图片服务器获取。
#
# C. 图像预处理和特征提取模块
#
#     将下载的图片进行标准化和大小调整，以符合ResNet50模型的输入要求。
#     将处理后的图像输入到ResNet50模型中，提取2048维的特征向量。
#
# D. 向量存储模块（Milvus客户端）
#
#     创建或选择Milvus中的集合（collection）用于存储向量。
#     将特征向量与其对应的属性信息一同存入Milvus。
#     确保数据的索引和检索可以通过产品编号或其他属性进行。
#
# E. 错误处理和日志记录模块
#
#     在整个流程中添加异常处理，确保系统的健壮性。
#     对关键操作进行日志记录，方便问题的调试和追踪。
#
# F. 配置管理模块
#
#     管理连接Kafka、MinIO和Milvus的配置参数。
#     使得这些参数易于调整和维护。
#
# G. 主控制器（主程序）
#
#     初始化所有模块，包括配置加载。
#     协调各个模块的工作流程。
#     管理错误和异常。
#
# 这是一个复杂项目，所以建议采用模块化和面向对象的方法进行编程。每个模块都应当是一个或多个类，这样便于维护和测试。此外，项目应该包含单元测试以确保各部分如预期工作，尤其是图片获取和特征提取模块，因为它们涉及外部依赖和复杂的数据处理。
#
#
# Q:
# 请按照项目大纲 A中，kafka消息队列监听模块代码给我实现连接(连接到Kafka服务器。订阅相关的Kafka主题。持续监听消息，并在接收到消息时触发图片获取流程。)，并且按照模块化和面向对象变成，请先将大纲A把代码给我
# kafka地址为： szsjhl-damai-mysql1-test-10-10-223-16-belle.lan:9092,szsjhl-damai-mysql-test-10-10-223-19-belle.lan:9092  相关topic为: bi_mdm_product_picture 其中消息格式为： {
#   "product_no": 20141205000036,
#   "brand_no": "BL",
#   "picture_url": "/2015/MDM/BL/BICX1198XU2DX1.jpg"
# }
#
# A:
# 基于您提供的信息，我们可以使用confluent-kafka-python客户端库来实现Kafka消息队列监听模块。以下是Python代码示例，它定义了一个类KafkaConsumerClient来处理与Kafka相关的操作。
#
# 请确保您已经安装了confluent-kafka库，您可以使用pip install confluent-kafka来安装它。
# from confluent_kafka import Consumer, KafkaException, KafkaError
# import sys
# import json
# import logging
#
# class KafkaConsumerClient:
#     def __init__(self, servers, topic):
#         # Kafka配置
#         self.kafka_conf = {
#             'bootstrap.servers': servers,  # Kafka集群地址
#             'group.id': 'mygroup',  # 消费者组标识
#             'session.timeout.ms': 6000,
#             'auto.offset.reset': 'earliest'  # 如果没有找到offset，从最早的消息开始消费
#         }
#         self.topic = topic
#
#     def on_assign(self, consumer, partitions):
#         # Optional: 在分区被分配后的回调函数
#         for p in partitions:
#             p.offset = 0  # 设置offset起始位置
#         consumer.assign(partitions)
#
#     def consume_messages(self):
#         # 创建Consumer实例
#         consumer = Consumer(self.kafka_conf)
#
#         # 设置分区分配的回调函数（如果需要）
#         consumer.subscribe([self.topic], on_assign=self.on_assign)
#
#         try:
#             while True:
#                 msg = consumer.poll(1.0)  # 从Kafka获取消息
#                 if msg is None:
#                     continue
#                 if msg.error():
#                     if msg.error().code() == KafkaError._PARTITION_EOF:
#                         # End of partition event
#                         sys.stderr.write('%% %s [%d] reached end at offset %d\n' %
#                                          (msg.topic(), msg.partition(), msg.offset()))
#                     elif msg.error():
#                         raise KafkaException(msg.error())
#                 else:
#                     # 正常消息
#                     msg_value = msg.value().decode('utf-8')
#                     message = json.loads(msg_value)
#                     self.process_message(message)
#         except KeyboardInterrupt:
#             sys.stderr.write('Aborted by user\n')
#         finally:
#             # 关闭Consumer实例的连接
#             consumer.close()
#
#     def process_message(self, message):
#         # 处理消息的逻辑
#         # TODO: 您可以在这里调用图片获取模块的方法来处理消息
#         print(f"Received message: {message}")
#
# if __name__ == "__main__":
#     logging.basicConfig(stream=sys.stderr, level=logging.INFO)
#     servers = 'szsjhl-damai-mysql1-test-10-10-223-16-belle.lan:9092,szsjhl-damai-mysql-test-10-10-223-19-belle.lan:9092'
#     topic = 'bi_mdm_product_picture'
#
#     # 创建Kafka消费者客户端实例
#     consumer_client = KafkaConsumerClient(servers, topic)
#     # 开始监听并消费消息
#     consumer_client.consume_messages()
# 这个KafkaConsumerClient类执行以下操作：
#
#     初始化时设置了Kafka的配置信息，包括服务器地址和消费者组信息。
#     一个consume_messages方法来不断轮询新消息。
#     一个process_message方法，它被consume_messages调用来处理收到的每个Kafka消息。
#
# 请根据您的实际需要，填充process_message方法的内容来触发图片获取流程。
#
# 您还需要处理连接问题、异常以及优雅地关闭连接，这个例子中已经包含了一个简单的异常处理和程序中断的情况处理。
#
# 请注意，您可能需要根据您的Kafka设置和安全要求调整配置参数。此代码仅为基础示例，实际生产环境中可能需要更详细的错误处理和日志记录策略。
#
#
# Q:
#
# 请按照项目大纲实现：B. 图片获取模块(
#     解析从Kafka接收到的消息，提取图片URL。
#     首先尝试从MinIO存储中获取图片。
#     如果MinIO中不存在图片，则通过HTTP请求从备用的图片服务器获取。) ,并且将a模块调用b模块的代码部分补充完成。
#
# A:
#
# 为了实现图片获取模块B，我们需要两个步骤：
#
#     首先尝试从MinIO存储中获取图片。
#     如果在MinIO中没有找到图片，我们需要通过HTTP请求从备用的图片服务器获取。
#
# 接下来，我们将创建两个类：MinIOClient用于处理与MinIO的交互，ImageFetcher用于协调图片的获取流程。为了简化，我们将使用requests库来从备用服务器获取图片，如果你使用其他服务则可能需要其他库。
#
# 首先安装必要的库：
#
# bash
#
# pip install minio requests
#
# 下面是图片获取模块的实现：
# from minio import Minio
# from minio.error import S3Error
# import requests
# import os
# from io import BytesIO
#
# class MinIOClient:
#     def __init__(self, endpoint, access_key, secret_key, bucket_name):
#         self.client = Minio(endpoint, access_key=access_key, secret_key=secret_key, secure=False)
#         self.bucket_name = bucket_name
#     def get_image(self, object_name):
#         try:
#             # 获取图片对象
#             response = self.client.get_object(self.bucket_name , object_name)
#             return BytesIO(response.read())
#         except S3Error as e:
#             print(f"MinIO error: {e}")
#             return None
#
# class ImageFetcher:
#     def __init__(self, minio_client, backup_image_server_url):
#         self.minio_client = minio_client
#         self.backup_image_server_url = backup_image_server_url
#
#     def fetch_image(self, image_path):
#         # 从MinIO中获取图片
#         image = self.minio_client.get_image( image_path)
#         if image:
#             return image
#
#         # 如果MinIO中没有找到图片，从备用服务器获取
#         full_url = self.backup_image_server_url + image_path
#         response = requests.get(full_url)
#         if response.status_code == 200:
#             return BytesIO(response.content)
#         else:
#             print(f"Failed to fetch image from backup server. Status code: {response.status_code}")
#             return None
#
# # KafkaConsumerClient类中调用图片获取
# class KafkaConsumerClient:
#     # ...其他代码保持不变
#
#     def __init__(self, servers, topic, image_fetcher):
#         # Kafka配置
#         self.kafka_conf = {
#             'bootstrap.servers': servers,
#             'group.id': 'mygroup',
#             'session.timeout.ms': 6000,
#             'auto.offset.reset': 'earliest'
#         }
#         self.topic = topic
#         self.image_fetcher = image_fetcher
#
#     # ...其他代码保持不变
#
#     def process_message(self, message):
#         # 解析消息获取图片路径
#         bucket_name = "your-bucket-name"  # MinIO存储桶名称
#         image_path = message['picture_url'].lstrip('/')  # 移除URL开头的斜杠
#         image = self.image_fetcher.fetch_image(bucket_name, image_path)
#         if image:
#             print(f"Image fetched successfully: {image_path}")
#             # 可以在这里进一步处理图片
#         else:
#             print(f"Failed to fetch image: {image_path}")
#
# # 主程序
# if __name__ == "__main__":
#     logging.basicConfig(stream=sys.stderr, level=logging.INFO)
#     servers = 'kafka-cluster:9092'
#     topic = 'bi_mdm_product_picture'
#     minio_endpoint = 'minio-server:9000'
#     minio_access_key = 'your-access-key'
#     minio_secret_key = 'your-secret-key'
#     backup_image_server_url = 'http://backup-image-server/'
#
#     # 创建MinIO客户端和图片获取器实例
#     minio_client = MinIOClient(minio_endpoint, minio_access_key, minio_secret_key)
#     image_fetcher = ImageFetcher(minio_client, backup_image_server_url)
#
#     # 创建Kafka消费者客户端实例，并传入图片获取器
#     consumer_client = KafkaConsumerClient(servers, topic, image_fetcher)
#
#     # 开始监听并消费消息
#     consumer_client.consume_messages()
# 在上述代码中，我们创建了MinIOClient来处理与MinIO的交互，尝试获取图片。如果在MinIO中没有找到图片，ImageFetcher会尝试从备用的图片服务器上获取图片。
#
# 请确保替换MinIO的配置参数（endpoint，access_key，secret_key）和MinIO存储桶的名称（bucket_name）以及备用服务器的URL（backup_image_server_url）为您的实
#
#
# Q:
# 请实现： D. 向量存储模块（Milvus客户端）
#     创建或选择Milvus中的集合（collection）用于存储向量。
#     将特征向量与其对应的属性信息一同存入Milvus。
#     确保数据的索引和检索可以通过产品编号或其他属性进行。 并将D模块可以嵌套上述模块，对于C模块我自己已经实现，在image_to_net类中，调用imgNet(img)即可完成向量化，请将其他部分代码实现。
#
# A:
# 要实现向量存储模块，我们将使用pymilvus，它是Milvus的官方Python SDK。此模块负责连接到Milvus数据库，创建或选择一个集合，然后将图片的特征向量及其属性信息存储到该集合中。我们还需要确保可以根据产品编号或其他属性对数据进行索引和检索。
#
# 首先，您需要安装pymilvus：
# from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
#
#
# class MilvusClient:
#     def __init__(self, host, port):
#         # 连接到Milvus服务器
#         connections.connect(host=host, port=port)
#         print(f"Connected to Milvus on: {host}:{port}")
#
#     def create_collection(self, collection_name, dim):
#         # 检查集合是否已存在
#         if utility.has_collection(collection_name):
#             print(f"Collection {collection_name} already exists.")
#             return
#
#         # 创建集合的字段（包括向量字段和属性字段）
#         fields = [
#             FieldSchema(name="product_no", dtype=DataType.INT64, is_primary=True),
#             FieldSchema(name="brand_no", dtype=DataType.VARCHAR, max_length=10),
#             FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim)
#         ]
#
#         # 创建集合
#         schema = CollectionSchema(fields, description="Product Image Collection")
#         collection = Collection(name=collection_name, schema=schema)
#         print(f"Created collection: {collection_name}")
#
#     def insert_data(self, collection_name, data):
#         # 插入数据到集合
#         collection = Collection(name=collection_name)
#         insert_result = collection.insert(data)
#         print(f"Inserted data into collection: {collection_name}")
#         return insert_result.primary_keys
#
#     def create_index(self, collection_name, field_name, index_type, metric_type):
#         # 为集合中的字段创建索引
#         collection = Collection(name=collection_name)
#         index_param = {
#             "index_type": index_type,
#             "metric_type": metric_type,
#             "params": {"nlist": 1024}
#         }
#         collection.create_index(field_name=field_name, index_params=index_param)
#         print(f"Created {index_type} index on field: {field_name}")
#
#
# # 使用示例
# # 假设 Milvus 服务运行在 localhost:19530
# milvus_client = MilvusClient(host='localhost', port=19530)
#
# # 创建或获取集合
# collection_name = 'product_image_collection'
# vector_dimension = 2048  # 假设您的向量维度为2048
# milvus_client.create_collection(collection_name, vector_dimension)
#
#
# # 假设您的imgNet类已经实现并且可以调用 imgNet(img) 来获取特征向量
# # image_to_net = imgNet()
#
# # Kafka消费者在处理消息时调用此方法来存储图片向量
# def store_image_vector(product_no, brand_no, image):
#     # 获取特征向量
#     vector = image_to_net.imgNet(image)
#     # 准备数据
#     data = [
#         {"product_no": product_no, "brand_no": brand_no, "embedding": vector}
#     ]
#     # 插入数据到Milvus集合
#     milvus_client.insert_data(collection_name, data)
# 在上述代码中，我们定义了MilvusClient类来处理与Milvus的所有交互。该类包含连接到Milvus的方法、创建集合、插入数据以及创建索引。
#
# 在实际使用中，您应当在程序开始时调用create_collection，以确保集合存在。之后，每次通过Kafka接收到新图片，并使用您的imgNet类将其转换为向量后，调用insert_data将数据插入到Milvus集合中。
#
# 还要注意，创建索引的操作通常是一次性的，可能会在集合创建后执行，或者在有足够的数据累积后执行以提高搜索效率。
#
# 这个模块可以和之前的Kafka消息监听模块以及图片获取模块结合使用，创建一个完整的图片向量化存储流
#
#
# Q:  请实现项目一下模块
# F. 配置管理模块
#
#     管理连接Kafka、MinIO和Milvus的配置参数。
#     使得这些参数易于调整和维护。
#
# G. 主控制器（主程序）
#
#     初始化所有模块，包括配置加载。
#     协调各个模块的工作流程。
#     管理错误和异常。
# 请详细完善主程序调用模块其中需要包含日志，错误重试，以及和其他模块配合调用方式
# A:
# 为了实现配置管理模块和主控制器，我们将采用如下策略：
#
#     使用一个配置文件来管理所有的配置参数。
#     创建一个配置加载器，用于从配置文件中读取配置信息。
#     实现主程序逻辑，其中包括初始化模块、协调工作流程，并处理错误和异常。
#
# 让我们首先定义配置文件，通常是一个.ini或.yaml格式的文件。在这个例子中，我们将使用.yaml格式。
#
# config.yaml:
#
# yaml
#
# kafka:
#   servers: "szsjhl-damai-mysql1-test-10-10-223-16-belle.lan:9092,szsjhl-damai-mysql-test-10-10-223-19-belle.lan:9092"
#   topic: "bi_mdm_product_picture"
#
# minio:
#   endpoint: "minio-server:9000"
#   access_key: "minioaccesskey"
#   secret_key: "miniosecretkey"
#   bucket_name: "product-images"
#
# milvus:
#   host: "localhost"
#   port: "19530"
#   collection_name: "product_image_collection"
#   vector_dimension: 2048
#
# backup_image_server:
#   url: "http://backup-image-server/"
#
# 现在，我们将创建一个配置管理器来加载这些设置。
#
# config_manager.py:
#
# python
#
# import yaml
#
# class ConfigManager:
#     def __init__(self, config_path):
#         self.config_path = config_path
#         self.config = self.load_config()
#
#     def load_config(self):
#         with open(self.config_path, 'r') as f:
#             return yaml.safe_load(f)
#
#     def get_kafka_config(self):
#         return self.config['kafka']
#
#     def get_minio_config(self):
#         return self.config['minio']
#
#     def get_milvus_config(self):
#         return self.config['milvus']
#
#     def get_backup_image_server_config(self):
#         return self.config['backup_image_server']
#
# 主程序main.py将会使用这个配置管理器，并初始化所有的模块，同时管理错误和异常。
#
# main.py:
#
# python
#
# import logging
# from config_manager import ConfigManager
# from kafka_consumer_client import KafkaConsumerClient
# from image_fetcher import ImageFetcher
# from milvus_client import MilvusClient
# from retry import retry
#
# # 配置日志
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)
#
# @retry(tries=3, delay=2)
# def main():
#     # 加载配置
#     config_manager = ConfigManager('config.yaml')
#     kafka_config = config_manager.get_kafka_config()
#     minio_config = config_manager.get_minio_config()
#     milvus_config = config_manager.get_milvus_config()
#     backup_image_server_config = config_manager.get_backup_image_server_config()
#
#     # 初始化模块
#     minio_client = MinIOClient(**minio_config)
#     image_fetcher = ImageFetcher(minio_client, backup_image_server_config['url'])
#     milvus_client = MilvusClient(milvus_config['host'], milvus_config['port'])
#
#     # 确保Milvus集合存在
#     milvus_client.create_collection(milvus_config['collection_name'], milvus_config['vector_dimension'])
#
#     # 初始化Kafka消费者
#     consumer_client = KafkaConsumerClient(kafka_config['servers'], kafka_config['topic'], image_fetcher)
#
#     # 开始处理消息
#     consumer_client.consume_messages()
#
# if __name__ == "__main__":
#     try:
#         main()
#     except Exception as e:
#         logger.error(f"Failed to run the main program: {e}", exc_info=True)
#
# 在main.py中，我们使用了一个retry装饰器，它将尝试运行main函数最多三次，如果遇到异常则在两秒后重试。这有助于处理暂时的网络问题或服务不稳定的情况。
#
# 我们也在main函数中添加了必要的错误处理，任何未捕获的异常都会被记录下来，并且终止程序。
#
# 所有这些模块，如KafkaConsumerClient、ImageFetcher、MinIOClient和MilvusClient，都假设您已经根据之前的讨论实现了它们。主程序将它们连接在一起，形成了完整的工作流程。在运行main.py之前，请确保所有依
# 赖都已经安装，并且服务（如Kafka、MinIO、Milvus和备用图片服务器）都是可访问的。
#
# 在主程序中，我们首先实例化ConfigManager来加载配置文件。之后，根据配置文件中的参数初始化MinIO客户端、图片获取器和Milvus客户端。然后，我们检查Milvus集合是否存在，如果不存在，则创建它。
#
# 在初始化Kafka消费者之后，我们开始消费消息。如果在处理消息时发生任何异常，retry装饰器会尝试重新执行main函数。如果连续失败超过三次，则记录异常并停止程序。
#
# 请确保你有正确处理各个模块中可能抛出的异常。例如，在ImageFetcher中，如果从MinIO获取图片失败，则应该尝试从备用服务器获取；如果仍然失败，则记录错误并且可以选择跳过当前消息或者停止程序。
#
# 还有一点要注意的是，根据你的实际需求，可能还需要添加信号处理，以便在程序需要优雅地终止时进行清理工作。
#
# 此外，为了确保日志信息有助于故障排除，在各个模块中详细记录日志也非常重要。你可以设置不同级别的日志记录，比如调试（DEBUG）、信息（INFO）、警告（WARNING）、错误（ERROR）和严重错误（CRITICAL）。
#
# 最后，要部署和运行这个系统，你可能还需要一个持续运行的环境，比如使用systemd服务在Linux上运行，或者在容器化环境中运行，如Docker或Kubernetes。
#
# 确保在部署之前，在本地或开发环境中充分测试每个组件的功能和错误处理逻辑。在更大规模的数据上测试系统的性能和稳定性也是很好的做法。




根据项目模块整理，我现在整理出一份完整项目代码，代码如下，请让我分批次输入完整项目代码，进行核验：
1. main程序代码：
    from image_search.config.logging_config import logger
    from image_search.config.config_util import ConfigManager
    from image_search.utils.kafka_util import KafkaConsumer
    from image_search.utils.image_fetcher import ImageFetcher,MinioClient,ImageRequest
    from image_search.utils.milvus_util import MilvusClient
    from image_search.utils.image_to_net_util import Net

    from retry import retry

    @retry(tries=3, delay=2)
    def main():
        # 加载配置
        config_manager = ConfigManager('../config/config.yaml')
        kafka_config = config_manager.get_kafka_config()
        minio_config = config_manager.get_minio_config()
        milvus_config = config_manager.get_milvus_config()
        # 初始化模块
        minio_client = MinioClient(endpoint=minio_config['endpoint'],access_key=minio_config['access_key'],secret_key=minio_config['secret_key'],bucket_name=minio_config['bucket_name'])
        img_req = ImageRequest()
        image_fetcher = ImageFetcher(minio_client, img_req)
        milvus_client = MilvusClient(host=milvus_config['host'],port=milvus_config['port'],user=milvus_config['user'],passwd=milvus_config['password'],database=milvus_config['database'],collection=milvus_config['collection'])
        emb_net = Net()
        # 初始化Kafka消费者
        consumer_client = KafkaConsumer(bootstrap_servers=kafka_config['servers'],topics=kafka_config['topic'], image_fetcher=image_fetcher, milvus_client= milvus_client, image_emb= emb_net)
        # 开始处理消息
        consumer_client.consume_messages()

    if __name__ == "__main__":
        try:
            main()
        except Exception as e:
            logger.error(f"Failed to run the main program: {e}", exc_info=True)
2:  Kafka消息队列监听模块（Kafka消费者） 模块代码
    from image_search.config.logging_config import logger
    from confluent_kafka import Consumer, KafkaException, KafkaError
    import json
    class KafkaConsumer:
        def __init__(self, topics, bootstrap_servers, image_fetcher, milvus_client,image_emb, group_id='image-search', auto_offset_reset='earliest'):
            self.consumer = Consumer({
                'bootstrap.servers': bootstrap_servers,
                'group.id': group_id,
                'auto.offset.reset': auto_offset_reset,
                'enable.auto.commit': True
            })
            self.topics = [topics]
            self.image_fetcher = image_fetcher
            self.milvus_client = milvus_client
            self.image_emb = image_emb
            logger.info("KafkaConsumer initialized.")

        def consume_messages(self):
            try:
                self.consumer.subscribe(self.topics)

                while True:
                    msg = self.consumer.poll(timeout=1.0)
                    if msg is None:
                        continue
                    if msg.error():
                        if msg.error().code() == KafkaError._PARTITION_EOF:
                            # End of partition event
                            logger.info('%% %s [%d] reached end at offset %d\n' %
                                         (msg.topic(), msg.partition(), msg.offset()))
                        elif msg.error():
                            raise KafkaException(msg.error())
                    else:
                        self.process_message(msg)

            except KafkaException as e:
                logger.error(f"Kafka error: {e}")
            except Exception as e:
                logger.error(f"Unexpected error: {e}")
            finally:
                self.consumer.close()

        def process_message(self, msg):
            # 在这里处理消息

            msg_value = msg.value().decode('utf-8')
            msg = json.loads(msg_value)
            picture_url = msg['picture_url']
            product_no = msg['product_no']
            brand_no = msg['brand_no']
            img_data = self.image_fetcher.fetch_image(picture_url)

            if img_data is None :
                logger.error(f'当前照片获取失败: {msg}')
            else:
                img_emb = self.image_emb.image_to_netvector(image=img_data)
                self.milvus_client.upsert_data(product_no=product_no,brand_no=brand_no,img_emb=img_emb,picture_url=picture_url)





3. 图片获取模块
    from image_search.config.logging_config import logger
    from io import BytesIO
    from minio import Minio
    from minio.error import S3Error
    from retry import retry
    from image_search.config.logging_config import logger
    import requests
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry

    class MinioClient:
        def __init__(self, endpoint, access_key, secret_key, bucket_name, secure=False):
            # 初始化minio客户端
            self.client = Minio(endpoint, access_key=access_key, secret_key=secret_key, secure=secure)
            self.bucket_name = bucket_name
            logger.info("Minio client 初始化完成")

        @retry(S3Error, tries=3, delay=2, backoff=2)
        def get_image(self, object_name):
            # 从Minio服务器获取对象
            object_name = 'bi-mdm' + object_name
            try:
                response = self.client.get_object(self.bucket_name, object_name)
                logger.info(f"Successfully retrieved {object_name} from bucket {self.bucket_name}")
                return response.data
            except S3Error as err:
                logger.error(f"An error occurred while trying to get object {object_name}: {err}")
                return None
            except Exception as err:
                logger.error(f"Unexpected error: {err}")
                return None


    class ImageRequest:
        SERVER_PREFIX = "https://pic.belle.net.cn/"
        def __init__(self):
            # 设置重试策略
            self.session = requests.Session()
            retries = Retry(total=5,
                            backoff_factor=0.1,
                            status_forcelist=[500, 502, 503, 504])
            self.session.mount('https://', HTTPAdapter(max_retries=retries))
            logger.info("request 初始化完成")

        def request_image(self, image_suffix):
            """
            根据图片URL的后缀获取图片数据。
            :param image_suffix: 图片URL的后缀
            :return: 一个图片转换为NumPy数组，如果有异常则返回None
            """
            image_url = f"{self.SERVER_PREFIX}{image_suffix}"
            try:
                response = self.session.get(image_url)
                response.raise_for_status()  # 如果响应状态码不是200，将引发HTTPError异常
                img_data = response.content
                logger.info(f"图片 {image_url} 获取成功。")
                return img_data
            except requests.exceptions.HTTPError as http_err:
                logger.error(f"HTTPS错误: {http_err}")
            except requests.exceptions.ConnectionError as conn_err:
                logger.error(f"连接错误: {conn_err}")
            except requests.exceptions.Timeout as timeout_err:
                logger.error(f"请求超时: {timeout_err}")
            except requests.exceptions.RequestException as req_err:
                logger.error(f"请求错误: {req_err}")
            except Exception as e:
                logger.error(f"在获取图片时发生未知错误: {e}")
            return None


    class ImageFetcher:
        def __init__(self, minio_client,img_req):
            self.minio_client = minio_client
            self.img_req = img_req

        def fetch_image(self,  image_path):
            # 从MinIO中获取图片
            image = self.minio_client.get_image( image_path)
            if image:
                return image
            else:
                # 如果MinIO中没有找到图片，从备用服务器获取
                image = self.img_req.request_image(image_path)
                # image = None
                return image

4. 向量存储模块（Milvus客户端）
    from image_search.config.logging_config import logger
    from pymilvus import (
        connections, utility, FieldSchema, CollectionSchema,
        DataType, Collection, db
    )

    from retry import retry
    class MilvusClient:
        def __init__(self, host='localhost', port='19530', user='', passwd='',database='', collection=''):
            connections.connect(user=user, password=passwd, host=host, port=port)
            db.using_database(database)
            # 建立到 Milvus 服务器的连接
            self.collection_name = collection
            self.product_no = 'product_no'
            self.brand_no = 'brand_no'
            self.img_emb = 'img_emb'
            self.picture_url = 'picture_url'
            logger.info(f"当前milvus连接成功: {host} - database: {database} -- collection: {collection}")
            # 创建集合和分区，如果它们不存在
            if not utility.has_collection(collection):
                logger.info(f'当前collection : {collection} 尚未创建。')
                self.create_collection(collection)

        def create_collection(self, collection_name):
            # 定义集合的 schema
            fields = [
                FieldSchema(name=self.product_no, dtype=DataType.INT64, is_primary=True, auto_id=False),
                FieldSchema(name=self.brand_no, dtype=DataType.VARCHAR, max_length=2048),
                FieldSchema(name=self.img_emb, dtype=DataType.FLOAT_VECTOR, dim=2048),
                FieldSchema(name=self.picture_url, dtype=DataType.VARCHAR, max_length=256)
            ]
            schema = CollectionSchema(fields, auto_id=False,
                                      description="Commodity Systems Department, Image Vectorization")
            index_params = {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            }

            collection = Collection(name=collection_name, schema=schema)  # Get an existing collection.

            #  创建索引
            collection.create_index(
                field_name=self.img_emb,
                index_params=index_params,
                index_name = "photo_vec_index"
            )
            collection.load()
            logger.info(f"Collection {collection.name} is created.")


        @retry(Exception, tries=3, delay=2, backoff=2)
        def upsert_data(self, product_no, brand_no, img_emb, picture_url):
            # 插入数据
            try:
                collection = Collection(self.collection_name)
                # 构建数据
                entities = [
                    [product_no],
                    [brand_no],
                    [img_emb],
                    [picture_url]
                ]

                if not collection.has_partition(brand_no):
                    collection.create_partition(brand_no)

                # 插入操作
                result = collection.upsert(entities)
                # 刷新集合以保证数据已写入
                collection.load()
                return result.primary_keys
            except Exception as e:
                logger.error(f"Error while upserting data with ID {id}: {e}")
                raise
5. 错误处理和日志记录模块
# -*- coding: utf-8 -*-
from loguru import logger
import os

# 创建日志目录
log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../logs")
os.makedirs(log_dir, exist_ok=True)

# 配置日志文件路径
log_file_path = os.path.join(log_dir, "image_search.log")

# 配置 Loguru 的 logger
logger.add(
    log_file_path,
    rotation="00:00",  # 在午夜时切割日志文件
    retention="30 days",  # 保留 30 天的日志
    encoding="utf-8",  # 设置编码为 UTF-8
    level="INFO"  # 日志级别为 INFO
)



# 根据项目模块整理，我现在整理出一份完整项目代码，代码如下，请让我分批次输入完整项目代码，进行核验：
# 1. main程序代码：
#     from image_search.config.logging_config import logger
#     from image_search.config.config_util import ConfigManager
#     from image_search.utils.kafka_util import KafkaConsumer
#     from image_search.utils.image_fetcher import ImageFetcher,MinioClient,ImageRequest
#     from image_search.utils.milvus_util import MilvusClient
#     from image_search.utils.image_to_net_util import Net
#
#     from retry import retry
#
#     @retry(tries=3, delay=2)
#     def main():
#         # 加载配置
#         config_manager = ConfigManager('../config/config.yaml')
#         kafka_config = config_manager.get_kafka_config()
#         minio_config = config_manager.get_minio_config()
#         milvus_config = config_manager.get_milvus_config()
#         # 初始化模块
#         minio_client = MinioClient(endpoint=minio_config['endpoint'],access_key=minio_config['access_key'],secret_key=minio_config['secret_key'],bucket_name=minio_config['bucket_name'])
#         img_req = ImageRequest()
#         image_fetcher = ImageFetcher(minio_client, img_req)
#         milvus_client = MilvusClient(host=milvus_config['host'],port=milvus_config['port'],user=milvus_config['user'],passwd=milvus_config['password'],database=milvus_config['database'],collection=milvus_config['collection'])
#         emb_net = Net()
#         # 初始化Kafka消费者
#         consumer_client = KafkaConsumer(bootstrap_servers=kafka_config['servers'],topics=kafka_config['topic'], image_fetcher=image_fetcher, milvus_client= milvus_client, image_emb= emb_net)
#         # 开始处理消息
#         consumer_client.consume_messages()
#
#     if __name__ == "__main__":
#         try:
#             main()
#         except Exception as e:
#             logger.error(f"Failed to run the main program: {e}", exc_info=True)
# 2:  Kafka消息队列监听模块（Kafka消费者） 模块代码
#     from image_search.config.logging_config import logger
#     from confluent_kafka import Consumer, KafkaException, KafkaError
#     import json
#     class KafkaConsumer:
#         def __init__(self, topics, bootstrap_servers, image_fetcher, milvus_client,image_emb, group_id='image-search', auto_offset_reset='earliest'):
#             self.consumer = Consumer({
#                 'bootstrap.servers': bootstrap_servers,
#                 'group.id': group_id,
#                 'auto.offset.reset': auto_offset_reset,
#                 'enable.auto.commit': True
#             })
#             self.topics = [topics]
#             self.image_fetcher = image_fetcher
#             self.milvus_client = milvus_client
#             self.image_emb = image_emb
#             logger.info("KafkaConsumer initialized.")
#
#         def consume_messages(self):
#             try:
#                 self.consumer.subscribe(self.topics)
#
#                 while True:
#                     msg = self.consumer.poll(timeout=1.0)
#                     if msg is None:
#                         continue
#                     if msg.error():
#                         if msg.error().code() == KafkaError._PARTITION_EOF:
#                             # End of partition event
#                             logger.info('%% %s [%d] reached end at offset %d\n' %
#                                          (msg.topic(), msg.partition(), msg.offset()))
#                         elif msg.error():
#                             raise KafkaException(msg.error())
#                     else:
#                         self.process_message(msg)
#
#             except KafkaException as e:
#                 logger.error(f"Kafka error: {e}")
#             except Exception as e:
#                 logger.error(f"Unexpected error: {e}")
#             finally:
#                 self.consumer.close()
#
#         def process_message(self, msg):
#             # 在这里处理消息
#
#             msg_value = msg.value().decode('utf-8')
#             msg = json.loads(msg_value)
#             picture_url = msg['picture_url']
#             product_no = msg['product_no']
#             brand_no = msg['brand_no']
#             img_data = self.image_fetcher.fetch_image(picture_url)
#
#             if img_data is None :
#                 logger.error(f'当前照片获取失败: {msg}')
#             else:
#                 img_emb = self.image_emb.image_to_netvector(image=img_data)
#                 self.milvus_client.upsert_data(product_no=product_no,brand_no=brand_no,img_emb=img_emb,picture_url=picture_url)
#
#
#
#
#
# 3. 图片获取模块
#     from image_search.config.logging_config import logger
#     from io import BytesIO
#     from minio import Minio
#     from minio.error import S3Error
#     from retry import retry
#     from image_search.config.logging_config import logger
#     import requests
#     from requests.adapters import HTTPAdapter
#     from urllib3.util.retry import Retry
#
#     class MinioClient:
#         def __init__(self, endpoint, access_key, secret_key, bucket_name, secure=False):
#             # 初始化minio客户端
#             self.client = Minio(endpoint, access_key=access_key, secret_key=secret_key, secure=secure)
#             self.bucket_name = bucket_name
#             logger.info("Minio client 初始化完成")
#
#         @retry(S3Error, tries=3, delay=2, backoff=2)
#         def get_image(self, object_name):
#             # 从Minio服务器获取对象
#             object_name = 'bi-mdm' + object_name
#             try:
#                 response = self.client.get_object(self.bucket_name, object_name)
#                 logger.info(f"Successfully retrieved {object_name} from bucket {self.bucket_name}")
#                 return response.data
#             except S3Error as err:
#                 logger.error(f"An error occurred while trying to get object {object_name}: {err}")
#                 return None
#             except Exception as err:
#                 logger.error(f"Unexpected error: {err}")
#                 return None
#
#
#     class ImageRequest:
#         SERVER_PREFIX = "https://pic.belle.net.cn/"
#         def __init__(self):
#             # 设置重试策略
#             self.session = requests.Session()
#             retries = Retry(total=5,
#                             backoff_factor=0.1,
#                             status_forcelist=[500, 502, 503, 504])
#             self.session.mount('https://', HTTPAdapter(max_retries=retries))
#             logger.info("request 初始化完成")
#
#         def request_image(self, image_suffix):
#             """
#             根据图片URL的后缀获取图片数据。
#             :param image_suffix: 图片URL的后缀
#             :return: 一个图片转换为NumPy数组，如果有异常则返回None
#             """
#             image_url = f"{self.SERVER_PREFIX}{image_suffix}"
#             try:
#                 response = self.session.get(image_url)
#                 response.raise_for_status()  # 如果响应状态码不是200，将引发HTTPError异常
#                 img_data = response.content
#                 logger.info(f"图片 {image_url} 获取成功。")
#                 return img_data
#             except requests.exceptions.HTTPError as http_err:
#                 logger.error(f"HTTPS错误: {http_err}")
#             except requests.exceptions.ConnectionError as conn_err:
#                 logger.error(f"连接错误: {conn_err}")
#             except requests.exceptions.Timeout as timeout_err:
#                 logger.error(f"请求超时: {timeout_err}")
#             except requests.exceptions.RequestException as req_err:
#                 logger.error(f"请求错误: {req_err}")
#             except Exception as e:
#                 logger.error(f"在获取图片时发生未知错误: {e}")
#             return None
#
#
#     class ImageFetcher:
#         def __init__(self, minio_client,img_req):
#             self.minio_client = minio_client
#             self.img_req = img_req
#
#         def fetch_image(self,  image_path):
#             # 从MinIO中获取图片
#             image = self.minio_client.get_image( image_path)
#             if image:
#                 return image
#             else:
#                 # 如果MinIO中没有找到图片，从备用服务器获取
#                 image = self.img_req.request_image(image_path)
#                 # image = None
#                 return image
#
# 4. 向量存储模块（Milvus客户端）
#     from image_search.config.logging_config import logger
#     from pymilvus import (
#         connections, utility, FieldSchema, CollectionSchema,
#         DataType, Collection, db
#     )
#
#     from retry import retry
#     class MilvusClient:
#         def __init__(self, host='localhost', port='19530', user='', passwd='',database='', collection=''):
#             connections.connect(user=user, password=passwd, host=host, port=port)
#             db.using_database(database)
#             # 建立到 Milvus 服务器的连接
#             self.collection_name = collection
#             self.product_no = 'product_no'
#             self.brand_no = 'brand_no'
#             self.img_emb = 'img_emb'
#             self.picture_url = 'picture_url'
#             logger.info(f"当前milvus连接成功: {host} - database: {database} -- collection: {collection}")
#             # 创建集合和分区，如果它们不存在
#             if not utility.has_collection(collection):
#                 logger.info(f'当前collection : {collection} 尚未创建。')
#                 self.create_collection(collection)
#
#         def create_collection(self, collection_name):
#             # 定义集合的 schema
#             fields = [
#                 FieldSchema(name=self.product_no, dtype=DataType.INT64, is_primary=True, auto_id=False),
#                 FieldSchema(name=self.brand_no, dtype=DataType.VARCHAR, max_length=2048),
#                 FieldSchema(name=self.img_emb, dtype=DataType.FLOAT_VECTOR, dim=2048),
#                 FieldSchema(name=self.picture_url, dtype=DataType.VARCHAR, max_length=256)
#             ]
#             schema = CollectionSchema(fields, auto_id=False,
#                                       description="Commodity Systems Department, Image Vectorization")
#             index_params = {
#                 "metric_type": "L2",
#                 "index_type": "IVF_FLAT",
#                 "params": {"nlist": 1024}
#             }
#
#             collection = Collection(name=collection_name, schema=schema)  # Get an existing collection.
#
#             #  创建索引
#             collection.create_index(
#                 field_name=self.img_emb,
#                 index_params=index_params,
#                 index_name = "photo_vec_index"
#             )
#             collection.load()
#             logger.info(f"Collection {collection.name} is created.")
#
#
#         @retry(Exception, tries=3, delay=2, backoff=2)
#         def upsert_data(self, product_no, brand_no, img_emb, picture_url):
#             # 插入数据
#             try:
#                 collection = Collection(self.collection_name)
#                 # 构建数据
#                 entities = [
#                     [product_no],
#                     [brand_no],
#                     [img_emb],
#                     [picture_url]
#                 ]
#
#                 if not collection.has_partition(brand_no):
#                     collection.create_partition(brand_no)
#
#                 # 插入操作
#                 result = collection.upsert(entities)
#                 # 刷新集合以保证数据已写入
#                 collection.load()
#                 return result.primary_keys
#             except Exception as e:
#                 logger.error(f"Error while upserting data with ID {id}: {e}")
#                 raise
# 5. 错误处理和日志记录模块
# # -*- coding: utf-8 -*-
# from loguru import logger
# import os
#
# # 创建日志目录
# log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../logs")
# os.makedirs(log_dir, exist_ok=True)
#
# # 配置日志文件路径
# log_file_path = os.path.join(log_dir, "image_search.log")
#
# # 配置 Loguru 的 logger
# logger.add(
#     log_file_path,
#     rotation="00:00",  # 在午夜时切割日志文件
#     retention="30 days",  # 保留 30 天的日志
#     encoding="utf-8",  # 设置编码为 UTF-8
#     level="INFO"  # 日志级别为 INFO
# )
